{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7499  | total loss: \u001b[1m\u001b[32m0.54970\u001b[0m\u001b[0m | time: 358.976s\n",
      "| Momentum | epoch: 015 | loss: 0.54970 - acc: 0.8452 -- iter: 49900/50000\n",
      "Training Step: 7500  | total loss: \u001b[1m\u001b[32m0.52815\u001b[0m\u001b[0m | time: 378.278s\n",
      "| Momentum | epoch: 015 | loss: 0.52815 - acc: 0.8517 | val_loss: 0.65203 - val_acc: 0.7782 -- iter: 50000/50000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\" Deep Residual Network.\n",
    "Applying a Deep Residual Network to CIFAR-10 Dataset classification task.\n",
    "References:\n",
    "    - K. He, X. Zhang, S. Ren, and J. Sun. Deep Residual Learning for Image\n",
    "      Recognition, 2015.\n",
    "    - Learning Multiple Layers of Features from Tiny Images, A. Krizhevsky, 2009.\n",
    "Links:\n",
    "    - [Deep Residual Network](http://arxiv.org/pdf/1512.03385.pdf)\n",
    "    - [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tflearn\n",
    "from tflearn.activations import softmax, relu\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, residual_block, global_avg_pool\n",
    "from tflearn.layers.normalization import batch_normalization\n",
    "from tflearn.optimizers import Momentum\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "# Residual blocks\n",
    "# 32 layers: n=5, 56 layers: n=9, 110 layers: n=18\n",
    "n = 2\n",
    "\n",
    "# Choose binarization type\n",
    "binarize = None\n",
    "\n",
    "# Set model name\n",
    "name='ResNet-2-basic'\n",
    "\n",
    "# Data loading\n",
    "from tflearn.datasets import cifar10\n",
    "(X, Y), (testX, testY) = cifar10.load_data()\n",
    "Y = tflearn.data_utils.to_categorical(Y, 10)\n",
    "testY = tflearn.data_utils.to_categorical(testY, 10)\n",
    "\n",
    "# Real-time data preprocessing\n",
    "img_prep = tflearn.ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center(per_channel=True)\n",
    "\n",
    "# Real-time data augmentation\n",
    "img_aug = tflearn.ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "\n",
    "# % Residual Network\n",
    "network = input_data(shape=[None, 32, 32, 3],\n",
    "                     data_preprocessing=img_prep,\n",
    "                     data_augmentation=img_aug)\n",
    "network = conv_2d(network, 16, 3, regularizer='L2', activation='relu', weight_decay=0.0001, binarize=binarize)\n",
    "network = residual_block(network, n, 16, binarize=binarize)\n",
    "network = residual_block(network, 1, 32, downsample=True, binarize=binarize)\n",
    "network = residual_block(network, n-1, 32, binarize=binarize)\n",
    "network = residual_block(network, 1, 64, downsample=True, binarize=binarize)\n",
    "network = residual_block(network, n-1, 64, binarize=binarize)\n",
    "network = batch_normalization(network)\n",
    "network = relu(network)\n",
    "network = global_avg_pool(network)\n",
    "\n",
    "# Regression\n",
    "network = fully_connected(network, 10, activation=None, binarize=binarize)\n",
    "network = softmax(network)\n",
    "mom = tflearn.Momentum(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\n",
    "network = regression(network, optimizer=mom, loss='categorical_crossentropy')\n",
    "# Training\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)\n",
    "\n",
    "model.fit(X, Y, n_epoch=15, validation_set=(testX, testY), show_metric=True, \n",
    "          batch_size=100, shuffle=True, run_id=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7078  | total loss: \u001b[1m\u001b[32m0.67836\u001b[0m\u001b[0m | time: 382.781s\n",
      "| Momentum | epoch: 015 | loss: 0.67836 - acc: 0.7757 -- iter: 49900/50000\n",
      "Training Step: 7079  | total loss: \u001b[1m\u001b[32m0.66133\u001b[0m\u001b[0m | time: 405.392s\n",
      "| Momentum | epoch: 015 | loss: 0.66133 - acc: 0.7831 | val_loss: 1.07522 - val_acc: 0.6431 -- iter: 50000/50000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, n_epoch=4, validation_set=(testX, testY), show_metric=True, \n",
    "          batch_size=100, shuffle=True, run_id=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
